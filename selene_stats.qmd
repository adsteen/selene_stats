---
title: "Testing differences in gene abundance among regions and pathotypes"
#format: html
format: gfm
editor: visual
cache: true
---

# Introduction

The purpose of this analysis is to assess potential differences in the distribution of a specific gene among microbes from a specific microbe. 

## ANOVA

A simple way to do this would be an ANOVA. Let's try and check whether the distributions of residuals and stability of variances look reasonable.

```{r, message=FALSE}
library(tidyverse)
library(MASS)
library(furrr)
library(tictoc)
library(rlang) # this is maybe needed by calculate_mean_diff
plan(multisession)
source("R/helper_funs.R")
theme_set(theme_classic()) 

# Read in raw zor-orz data
region <- readxl::read_xlsx("data/FINAL data for Steen.xlsx", 
                            sheet = "zor-orz gene number",
                            range = "A11:G18") %>%
  rename(gene.count = Continent) %>%
  pivot_longer(-1, names_to = "category", values_to = "count") %>%
  group_by(category) %>%
  mutate(freq = count / sum(count, na.rm = TRUE))
  
path <- readxl::read_xlsx("data/FINAL data for Steen.xlsx", 
                            sheet = "zor-orz gene number",
                            range = "A1:E8") %>%
  rename(gene.count = Pathotype) %>%
  pivot_longer(-1, names_to = "category", values_to = "count") %>%
  group_by(category) %>%
  mutate(freq = count / sum(count, na.rm = TRUE))




raw_region_data <- recreate_raw(region) %>%
  arrange(category) # this appears to have worked
raw_path_data <- recreate_raw(path)

raw_plot <- function(df) {
  p <- ggplot(df, aes(x=category, y=gene.count)) + 
  geom_boxplot() + 
  #geom_point(position=position_jitter(height = 0.3), alpha = 0.5) + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle=-45, hjust=0))
  p
}

p_region <- raw_plot(raw_region_data)
p_path <- raw_plot(raw_path_data)

raw_line_plot <- function(df) {
  p <- ggplot(df, aes(x=gene.count, y=freq, color=category)) + 
    geom_point() + 
    geom_line()  + 
    scale_color_brewer(type="qual")
  p
}

raw_bar_plot <- function(df) {
  p <- ggplot(df, aes(x=gene.count, y=freq, fill=category)) + 
    geom_bar(stat="identity", position="dodge") + 
    scale_fill_brewer(type="qual")
  p
}

# Make up plots for later display
p_reg_line <- raw_line_plot(raw_region_data)
p_path_line <- raw_line_plot(raw_path_data)
p_reg_bar <- raw_bar_plot(raw_region_data)
p_path_bar <- raw_bar_plot(raw_path_data)
```

I'm not really sure what the best way to display these is, so I'm giving three options:

```{r, plot=TRUE, echo=FALSE, fig.height=7, fig.width=8}
cowplot::plot_grid(p_region, p_path,
                   p_reg_line, p_path_line,
                   p_reg_bar, p_path_bar,
                   nrow=3)
```

These data sets have some subtle differences in distributions among pathotypes/regions, which are easiest to see in the middle row of colored line plots. Is a linear model (ANOVA) good for these data? Specifically: ANOVA is fairly robust to unbalanced designs and to heteroskedasticity, but not to hetereoskedastic data in an unbalanced design. So let's check the heteroskedasticity.

### Linear model for regions

```{r}
region_model <- lm(gene.count ~ category, data=raw_region_data)
summary(aov(region_model))
```

This model finds signficant differences among regions. But before we take this too seriously, let's check whether the residuals are normally distributed. A good way to do that is via a QQ plot. The

```{r}
plot(region_model, which=2) 
```

I'd say we these residuals are sufficiently non-normally distributed that a linear model is not a good choice for the regional data.

![](https://64.media.tumblr.com/f8b7a14c2fa304a712b5f92ea14d62f9/tumblr_n41bxrhleZ1rvirvyo1_400.gif)

### Linear model for pathotypes

```{r}
path_model <- lm(gene.count ~ category, data=raw_path_data)
summary(aov(path_model))
```

Again, significant differences among pathotypes.

```{r}
plot(path_model, which=2)
```

Same situation here. The QQ-plot is sufficiently not-like-a-straight-line that I don't really want to interpret the p values that come from it.

## Poisson distribution?

I propose that we can think of gene distribution as a poisson process, where different values of $\lambda$ indicate different probabilities of the gene being "handed out". If this is the case, we can assess whether there are difference in lambda among regions or pathotypes - but first we need to assess whether the data are, in fact, poisson-distributed. We'll simply load the data, fit it to a poisson distribution, and see whether the fit looks good. I think in this case a qualitative assessment is at least as good as some kind fo statistical test of goodness-of-fit.

```{r, message = FALSE, warning=FALSE}
d <- rbind(region %>% mutate(type="region"),
           path %>% mutate(type="path")) %>%
  mutate(category=factor(category, levels = c("Africa","Asia", "Europe", "North America", "Oceania", "South America", "pa", "healthy", "intestinal disease", "urinary disease"), ordere=TRUE))

ggplot(d, aes(x=gene.count, y=count)) + 
  geom_point() + 
  facet_wrap(~category, scale="free_y")
```

These data do not look poisson-distributed. I'm pretty sure that part of the issue is there is correlation between the two genes in terms of whether they are likely to appear in hte genome - that is, if one of the genes is present, the other is likely to be as well. Note there are almost never exactly 3 genes present. So, I don't really want to model this with Poisson distributions.

```{r, echo=FALSE, include=FALSE, message=FALSE}
### Fit each category to its own poisson model
# function to fit the model
pois_fit <- function(df) {
  MASS::fitdistr(df$gene.count, 
               densfun=dpois, 
               start=list(lambda = 1)) 
}

d_nest <- d %>%
  group_by(category) %>%
  nest() %>%
  mutate(pois_fits = map(data, pois_fit),
         lambdas = map_dbl(pois_fits,  function(x) x$estimate))
  
```

# Monte Carlo simulations

I think it is more robust to do a Monte Carlo simulation of variation in the ANOVA *f* ratio.

```{r}
# Set the number of monte carlo replicates
n <- 10000
nrow.reg <- nrow(region)
nrow.path <- nrow(path)


tic()
reg.f.vec <- future_map_dbl(seq_along(1:n), 
                            shuf_calc_f, 
                            df=region, nrow=nrow.reg, 
                             .options = furrr_options(seed = TRUE)) 
path.f.vec <- future_map_dbl(seq_along(1:n), 
                             shuf_calc_f, 
                             df=path, nrow=nrow.path, 
                             .options = furrr_options(seed = TRUE)) 
toc() # Runs in about 14 seconds on 6 core macbook pro; pretty sweet

# put the simulated f values in a data frame
f_vals <- data.frame(reg.sim.f = reg.f.vec,
                     path.sim.f = path.f.vec)
```

```{r}
# Pull out actual f values
reg.f.real <- summary(aov(region_model))[[1]][1,4]
path.f.real <- summary(aov(path_model))[[1]][1,4]
```

How do the real f values compare to the simulated, null-hypothesis values?

```{r}
p_reg_hist <- ggplot(f_vals, aes(x=reg.sim.f)) + 
  geom_histogram(bins = 100) + 
  geom_vline(xintercept = reg.f.real, color="red")  + 
  ggtitle("data by region")
print(p_reg_hist)
```

```{r}
p_path_hist <- ggplot(f_vals, aes(x=path.sim.f)) + 
  geom_histogram(bins = 100) + 
  geom_vline(xintercept = path.f.real, color="red") + 
  ggtitle("data by pathology")
print(p_path_hist)
```

So: I have simulated `r format(n, scientific=FALSE, big.mark=",")` and found that, for each case, the actual measured *f* values are much, much larger than they would be likely to be if the null hypothesis were true - so much larger that we can't calculate a p value, because none of our `r format(n, scientific=FALSE, big.mark=",")` simulations captured a *f* value that big. We can say conservatively say that, in each case, p \< 0.0001.

In summary:

```{r, echo=FALSE}
sim.max.f.print.path <- max(f_vals$path.sim.f) %>%
  format(digits = 2)
sim.max.f.print.reg <- max(f_vals$reg.sim.f) %>%
  format(digits = 2)
actual.f.path <- path.f.real %>%
  format(digits = 2)
actual.f.reg <- reg.f.real %>%
  format(digits = 2)
```

| f-value      | Simulated maximum        | Observed          |
|--------------|--------------------------|-------------------|
| by pathology | `r sim.max.f.print.path` | `r actual.f.path` |
| by region    | `r sim.max.f.print.reg`  | `r actual.f.reg`  |


# Monte Carlo Tukey Test 

A Tukey test works by comparing means of all possible combinations of populations (in this case, regions or pathotypes) and then comparing to a studentized range distribution. I'm going to do exactly this, except that the studentized range distribution is replaced with the observed distribution of mean differences in shuffled data. 

```{r}
# Let's make a function to calculate actual means and then simulated means
tic()
n.tukey <- 1e4
path_diffs <- monte_carlo_tukey(raw_path_data, n.tukey)
region_diffs <- monte_carlo_tukey(raw_region_data, n.tukey)
toc()
```
# Results

## zor-orz results

```{r}
knitr::kable(path_diffs)
```
### How to interpret this table

This is a table comparing differences in the mean gene number between each pair of groups. For instance, the top row is `Africa-Asia`, `mean.diff` indicates that the absolute value of the difference in the mean number of zor/orz genes between Africa and Asia is 0.091. `cutoff.diff`, the "cutoff" above which a difference would be statistically significant (p < 0.05), is 0.286. 0.091 is not greater than 0.286, so there is no significant difference. Thus, the `sig.diff` entry is FALSE.

`Asia-North America`, does have a significant difference: `cutoff.diff` is 0.087, `mean.diff` is 0.183, so `sig.diff` is TRUE.  
```{r}
knitr::kable(region_diffs)
```

# tisB - istR analysis

We want to do the same analysis for the tisB-istR gene pair. 

First load the data. 

```{r}
# Read in raw zor-orz data
tisB_region <- readxl::read_xlsx("data/FINAL data for Steen.xlsx", 
                            sheet = "tisB-istR gene number",
                            range = "A11:G13") %>%
  rename(gene.count = Continent) %>%
  pivot_longer(-1, names_to = "category", values_to = "count") %>%
  group_by(category) %>%
  mutate(freq = count / sum(count, na.rm = TRUE))

tisB_path <- readxl::read_xlsx("data/FINAL data for Steen.xlsx", 
                            sheet = "tisB-istR gene number",
                            range = "A1:E3") %>%
  rename(gene.count = Pathotype) %>%
  pivot_longer(-1, names_to = "category", values_to = "count") %>%
  group_by(category) %>%
  mutate(freq = count / sum(count, na.rm = TRUE))

raw_region_tisB <- recreate_raw(tisB_region) %>%
  arrange(category) # this appears to have worked
raw_path_tisB <- recreate_raw(tisB_path) %>%
  arrange(category)


tic()
tisB_region_diffs <- monte_carlo_tukey(raw_region_tisB, n=n.tukey)
tisB_path_diffs <- monte_carlo_tukey(raw_path_tisB, n=n.tukey)
toc()
```
## tisB-istR regional differences
```{r}
knitr::kable(tisB_region_diffs)
```

## tisB-istR pathotype differences

```{r}
knitr::kable(tisB_path_diffs)
```

